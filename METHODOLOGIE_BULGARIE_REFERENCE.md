# üìã M√âTHODOLOGIE BULGARIE - R√âF√âRENCE ABSOLUE

**Version :** 1.0  
**Date :** 5 d√©cembre 2025  
**Statut :** ‚úÖ VALID√âE - Taux de r√©ussite 88.9% sur pattern dominant  
**Application :** TOUTES les ligues doivent suivre cette m√©thodologie EXACTEMENT

---

## üéØ OBJECTIF

Scraper les donn√©es historiques des matchs pour identifier les **patterns de buts r√©currents** par √©quipe, localisation (HOME/AWAY) et intervalle de temps.

---

## üìä ARCHITECTURE COMPL√àTE

### 1Ô∏è‚É£ SCRAPING (scrape_bulgaria_auto.py)

#### **√âTAPE 1 : Extraction des codes √©quipes**

**URL source :** `https://www.soccerstats.com/formtable.asp?league={league_code}`

**M√©thode :**
```python
def extract_team_codes(league_code: str) -> List[Tuple[str, str]]:
    """
    Extraire tous les codes √©quipes depuis formtable.asp
    
    Returns:
        Liste de tuples (code_equipe, nom_equipe)
        Exemple: [('u1749-cska-sofia', 'CSKA Sofia'), ...]
    """
    # 1. Parser la page formtable.asp
    # 2. Chercher tous les liens <a href="teamstats.asp?league=bulgaria&stats=u{id}-{nom}">
    # 3. Extraire le pattern : stats=(u\d+-[^&]+)
    # 4. D√©dupliquer et trier
```

**Output attendu :**
```
‚úÖ 16 √©quipes trouv√©es :
   ‚Ä¢ u1749-cska-sofia                ‚Üí CSKA Sofia
   ‚Ä¢ u1750-levski-sofia              ‚Üí Levski Sofia
   ‚Ä¢ u1752-ludogorets                ‚Üí Ludogorets
   ...
```

---

#### **√âTAPE 2 : Scraping par √©quipe (parall√©lis√©)**

**URL source :** `https://www.soccerstats.com/teamstats.asp?league={league_code}&stats={team_code}`

**M√©thode :**
```python
def scrape_team(league_code: str, team_code: str, team_name: str) -> List[dict]:
    """
    Scraper tous les matches d'une √©quipe
    
    Extraction :
    1. Date du match (colonne 0)
    2. √âquipe domicile (colonne 1) - en GRAS si c'est l'√©quipe principale
    3. Score (colonne 2) - avec tooltip HTML contenant les minutes de buts
    4. √âquipe ext√©rieur (colonne 3)
    5. Score mi-temps (colonne 7)
    
    Returns:
        Liste de dictionnaires avec :
        - country, league, league_code, team, opponent, date
        - is_home (True/False)
        - score, ht_score
        - goals_scored: [13, 35, 58] (minutes des buts MARQU√âS)
        - goals_conceded: [21, 67] (minutes des buts ENCAISS√âS)
    """
```

**Extraction des buts depuis tooltip HTML :**
```python
def _extract_goals_from_tooltip(tooltip_html: str, team_is_home: bool):
    """
    Parser le tooltip pour extraire les minutes de buts
    
    Structure tooltip :
    <span>
        <font color="red">0-<b>1</b></font> (13) Joueur A<br>
        <b>1</b>-1 (35) Joueur B<br>
        1-<font color="red"><b>2</b></font> (67) Joueur C<br>
    </span>
    
    Logique :
    1. Trouver tous les <b>X-Y</b> (scores progressifs)
    2. Extraire la minute (\d+) entre parenth√®ses
    3. Comparer X-Y avec score pr√©c√©dent pour savoir qui a marqu√©
    4. Si HOME score augmente :
       - team_is_home=True ‚Üí goals_scored
       - team_is_home=False ‚Üí goals_conceded
    5. Si AWAY score augmente :
       - team_is_home=True ‚Üí goals_conceded
       - team_is_home=False ‚Üí goals_scored
    
    Returns:
        (goals_scored, goals_conceded) : Listes de minutes [int]
    """
```

**Parall√©lisation :**
```python
# 3-4 workers maximum pour respecter le serveur
with ThreadPoolExecutor(max_workers=4) as executor:
    futures = {executor.submit(scrape_team, code, name): (code, name) for code, name in teams}
    
# Throttling : 2-3 secondes entre chaque requ√™te
time.sleep(2)
```

---

#### **√âTAPE 3 : Sauvegarde en base de donn√©es**

**Table :** `soccerstats_scraped_matches`

**Structure :**
```sql
CREATE TABLE soccerstats_scraped_matches (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    country TEXT,                    -- 'Bulgaria'
    league TEXT,                     -- 'bulgaria' (code)
    league_display_name TEXT,        -- 'A PFG' (nom affich√©)
    team TEXT,                       -- 'CSKA Sofia'
    opponent TEXT,                   -- 'Levski Sofia'
    date TEXT,                       -- '06.05'
    is_home INTEGER,                 -- 1=HOME, 0=AWAY
    score TEXT,                      -- '2-1'
    goals_for INTEGER,               -- 2
    goals_against INTEGER,           -- 1
    goal_times TEXT,                 -- '[13, 35, 0, 0, 0, 0, 0, 0, 0, 0]' (JSON)
    goal_times_conceded TEXT,        -- '[67, 0, 0, 0, 0, 0, 0, 0, 0, 0]' (JSON)
    match_id TEXT UNIQUE,            -- '06.05_CSKA Sofia_vs_Levski Sofia'
    scraped_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**‚ö†Ô∏è FORMAT CRITIQUE - goal_times :**
```python
# TOUJOURS un array de 10 √©l√©ments avec padding de z√©ros
goals_scored = [13, 35, 58]  # 3 buts aux minutes 13, 35, 58

# Transformation pour DB (padding √† 10 √©l√©ments)
goal_times_json = [13, 35, 58, 0, 0, 0, 0, 0, 0, 0]

# Code exact :
goal_times = match['goals_scored'] + [0] * (10 - len(match['goals_scored']))
goal_times_json = json.dumps(goal_times[:10])
```

**Gestion des doublons (m√©thode SELECT-UPDATE/INSERT) :**
```python
def save_to_db(matches_data: List[dict]):
    """
    Sauvegarde avec pr√©vention des doublons
    
    Logique :
    1. Pour chaque match, g√©n√©rer match_id unique
    2. SELECT pour v√©rifier existence (team + opponent + date + is_home)
    3. Si existe ‚Üí UPDATE (mettre √† jour les donn√©es)
    4. Sinon ‚Üí INSERT (nouveau match)
    """
    for match in matches_data:
        # 1. G√©n√©rer match_id
        team1, team2 = sorted([match['team'], match['opponent']])
        match_id = f"{match['date']}_{team1}_vs_{team2}"
        
        # 2. V√©rifier existence
        cursor.execute('''
            SELECT COUNT(*) FROM soccerstats_scraped_matches 
            WHERE team = ? AND opponent = ? AND date = ? AND is_home = ?
        ''', (match['team'], match['opponent'], match['date'], 1 if match['is_home'] else 0))
        
        if cursor.fetchone()[0] > 0:
            # 3a. UPDATE si existe
            cursor.execute('''UPDATE soccerstats_scraped_matches SET ...''')
            updated += 1
        else:
            # 3b. INSERT si nouveau
            cursor.execute('''INSERT INTO soccerstats_scraped_matches ...''')
            inserted += 1
```

**Output attendu :**
```
üíæ Sauvegarde : 128 nouveaux, 0 mis √† jour

‚úÖ Scraping termin√© !
   ‚Ä¢ √âquipes scrap√©es : 16/16
   ‚Ä¢ Matches collect√©s : 128
   ‚Ä¢ Ins√©r√©s en DB : 128
```

---

### 2Ô∏è‚É£ ANALYSE DES PATTERNS (top_patterns_bulgaria.py)

#### **Intervalles de temps standards**

```python
def get_interval(minute):
    """
    Cat√©gorisation standard des minutes de jeu
    """
    if 0 <= minute <= 15: return '0-15'      # D√©but de match
    elif 16 <= minute <= 30: return '16-30'  # Milieu 1√®re MT
    elif 31 <= minute <= 45: return '31-45'  # Fin 1√®re MT ‚≠ê
    elif 46 <= minute <= 60: return '46-60'  # D√©but 2√®me MT
    elif 61 <= minute <= 75: return '61-75'  # Milieu 2√®me MT
    elif 76 <= minute <= 90: return '76-90'  # Fin de match üî•
    return None
```

**Focus principal :** `31-45` (fin 1√®re mi-temps) et `76-90` (fin de match)

---

#### **M√âTHODE DE CALCUL DE LA R√âCURRENCE**

**‚ö†Ô∏è CRITIQUE - NE PAS CONFONDRE :**

```python
# ‚ùå FAUX (ce que j'ai fait au d√©but)
recurrence = (nombre_total_de_buts_dans_intervalle / nombre_total_matchs) * 100

# ‚úÖ CORRECT (m√©thode Bulgarie valid√©e)
recurrence = (nombre_de_matchs_AVEC_au_moins_1_but_dans_intervalle / nombre_total_matchs) * 100
```

**Exemple concret :**

Brentford HOME en 76-90 :
- 7 matchs jou√©s
- 7 buts marqu√©s dans l'intervalle 76-90
- Mais r√©partis sur seulement **4 matchs diff√©rents**

```python
# ‚ùå Mauvais calcul
recurrence = (7 buts / 7 matchs) * 100 = 100.0% ‚ùå

# ‚úÖ Bon calcul
matchs_avec_but = 4  # Matchs o√π au moins 1 but en 76-90
recurrence = (4 matchs / 7 matchs) * 100 = 57.1% ‚úÖ
```

---

#### **Code de r√©f√©rence exact**

```python
def analyze_patterns():
    """
    Analyser les patterns de buts par √©quipe/localisation/intervalle
    
    M√âTHODE BULGARIE VALID√âE
    """
    conn = sqlite3.connect('predictions.db')
    cursor = conn.cursor()
    
    # Structure de donn√©es
    match_has_goal_in_interval = defaultdict(lambda: defaultdict(list))
    match_counts = defaultdict(int)
    
    cursor.execute("""
        SELECT team, is_home, goal_times, goal_times_conceded, date, opponent
        FROM soccerstats_scraped_matches 
        WHERE league = 'bulgaria'
    """)
    
    for row in cursor.fetchall():
        team = row[0]
        is_home = "HOME" if row[1] == 1 else "AWAY"
        goals_scored = json.loads(row[2])
        goals_conceded = json.loads(row[3])
        date = row[4]
        opponent = row[5]
        
        key = f"{team} {is_home}"
        match_counts[key] += 1
        match_id = f"{date}_{opponent}"
        
        # Pour CE MATCH, quels intervalles ont au moins 1 but ?
        intervals_with_goals = set()
        
        # Buts marqu√©s
        for minute in goals_scored:
            if minute > 0:
                interval = get_interval(minute)
                if interval:
                    intervals_with_goals.add(interval)
        
        # Buts encaiss√©s
        for minute in goals_conceded:
            if minute > 0:
                interval = get_interval(minute)
                if interval:
                    intervals_with_goals.add(interval)
        
        # Enregistrer ce match pour chaque intervalle concern√©
        for interval in intervals_with_goals:
            match_has_goal_in_interval[key][interval].append(match_id)
    
    # Calculer les r√©currences
    patterns = {}
    for key in match_counts:
        patterns[key] = {}
        for interval in ['0-15', '16-30', '31-45', '46-60', '61-75', '76-90']:
            # Nombre de matchs DIFF√âRENTS avec au moins 1 but dans cet intervalle
            matches_with_goal = len(set(match_has_goal_in_interval[key][interval]))
            total_matches = match_counts[key]
            
            recurrence = (matches_with_goal / total_matches) * 100 if total_matches > 0 else 0
            
            patterns[key][interval] = {
                'matches_with_goal': matches_with_goal,
                'total_matches': total_matches,
                'recurrence': recurrence
            }
    
    return patterns
```

---

#### **Crit√®res de filtrage et classement**

**Seuils de qualit√© :**

```python
# Filtres minimaux
MIN_MATCHES_WITH_GOAL = 3  # Au moins 3 matchs avec but dans l'intervalle
MIN_RECURRENCE = 40.0      # Au moins 40% de r√©currence

# Classification
if recurrence >= 70: status = "üî•"  # Excellent
elif recurrence >= 50: status = "‚≠ê"  # Tr√®s bon
elif recurrence >= 40: status = "‚úÖ"  # Exploitable
else: status = "üìä"  # Informatif seulement
```

**Tri :**
```python
# Toujours trier par R√âCURRENCE d√©croissante
results.sort(key=lambda x: x['recurrence'], reverse=True)
```

---

#### **Format d'affichage standard**

```python
print(f"{rank:2}. {status} {team:30} {location:4} {interval:6} : "
      f"{matches_with_goal}/{total_matches} matchs = {recurrence:5.1f}%")

# Exemple output :
# 1. üî• CSKA Sofia               HOME 76-90 : 6/7 matchs =  85.7%
# 2. ‚≠ê Ludogorets              AWAY 76-90 : 5/9 matchs =  55.6%
# 3. ‚úÖ Levski Sofia            HOME 31-45 : 4/9 matchs =  44.4%
```

---

## üîç R√âSULTATS VALID√âS BULGARIE

**Dataset :** 128 matchs, 16 √©quipes  
**Pattern dominant :** CSKA Sofia HOME 76-90 = **85.7% r√©currence** (6/7 matchs)  
**Validation terrain :** 88.9% de r√©ussite sur pattern dominant

**Distribution globale buts :**
```
1-15   :  12.2%
16-30  :  10.4%
31-45  :  19.3% ‚≠ê (fin 1√®re MT)
46-60  :  16.3%
61-75  :  14.2%
76-90  :  27.5% üî• (fin de match - DOMINANT)
```

---

## ‚úÖ CHECKLIST D'APPLICATION AUTRES LIGUES

### Avant de scraper une nouvelle ligue :

- [ ] V√©rifier URL formtable.asp avec le bon league_code
- [ ] Tester extraction codes √©quipes (√âTAPE 1)
- [ ] V√©rifier structure HTML de teamstats.asp (peut varier l√©g√®rement)
- [ ] Tester extraction tooltip sur 1 √©quipe
- [ ] Valider format goal_times (toujours 10 √©l√©ments avec padding)

### Pendant le scraping :

- [ ] Throttling 2-3 secondes entre requ√™tes
- [ ] Max 4 workers parall√®les
- [ ] V√©rifier que DB ne s'efface PAS (SELECT-UPDATE/INSERT)
- [ ] Logger les erreurs sans bloquer le processus

### Apr√®s le scraping :

- [ ] V√©rifier nombre √©quipes scrap√©es = nombre attendu
- [ ] V√©rifier balance buts : SUM(goals_for) = SUM(goals_against)
- [ ] Tester analyse patterns avec VRAIE m√©thode r√©currence
- [ ] Comparer distribution 76-90 avec Bulgarie (~27-30%)

---

## üö® ERREURS √Ä NE JAMAIS REPRODUIRE

### ‚ùå Erreur #1 : Mauvais calcul de r√©currence
```python
# FAUX
recurrence = (total_buts / total_matchs) * 100  # ‚ùå

# CORRECT
recurrence = (matchs_avec_but / total_matchs) * 100  # ‚úÖ
```

### ‚ùå Erreur #2 : Effacement donn√©es lors nouveau scraping
```python
# FAUX - Efface TOUT
cursor.execute("DELETE FROM soccerstats_scraped_matches")  # ‚ùå

# CORRECT - Efface seulement la ligue concern√©e
cursor.execute("DELETE FROM soccerstats_scraped_matches WHERE league = ?", (league_code,))  # ‚úÖ
```

### ‚ùå Erreur #3 : Goal_times de taille variable
```python
# FAUX
goal_times = [13, 35]  # ‚ùå Array de 2 √©l√©ments

# CORRECT
goal_times = [13, 35, 0, 0, 0, 0, 0, 0, 0, 0]  # ‚úÖ Toujours 10 √©l√©ments
```

### ‚ùå Erreur #4 : Utiliser json_array_length() en SQL
```python
# FAUX - Compte les z√©ros aussi
SELECT AVG(json_array_length(goal_times)) FROM ...  # ‚ùå Retourne 10.0 toujours

# CORRECT - Filtrer en Python
goals_count = sum(1 for g in json.loads(goal_times) if g > 0)  # ‚úÖ
```

---

## üìù TEMPLATE CODE NOUVELLE LIGUE

```python
#!/usr/bin/env python3
"""
Scraper pour {LIGUE_NAME}
Suit EXACTEMENT la m√©thodologie Bulgarie valid√©e
"""

# Copier scrape_bulgaria_auto.py
# Modifier seulement :
# - league_code (ex: "france", "england", "spain")
# - country (ex: "France", "England", "Spain")
# - league_display (ex: "Ligue 1", "Premier League", "La Liga")

# NE PAS MODIFIER :
# - Structure extract_team_codes()
# - Logique _extract_goals_from_tooltip()
# - Format goal_times (10 √©l√©ments)
# - M√©thode save_to_db() SELECT-UPDATE/INSERT
# - Throttling et workers
```

---

## üîÑ SCRAPING HEBDOMADAIRE ET MAINTENANCE

### Strat√©gie de mise √† jour (1x par semaine)

**Objectif :** Garder les donn√©es √† jour sans cr√©er de doublons

**M√©thode recommand√©e : DELETE + INSERT FULL**

```python
# Option A : DELETE puis INSERT (SIMPLE, FIABLE)
def weekly_update(league_code: str):
    """
    Mise √† jour hebdomadaire compl√®te
    
    Avantages :
    - Pas de risque de doublons
    - Donn√©es toujours fra√Æches
    - Simple √† maintenir
    
    Inconv√©nients :
    - Efface tout (mais c'est voulu)
    """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # 1. Supprimer SEULEMENT cette ligue
    cursor.execute(
        "DELETE FROM soccerstats_scraped_matches WHERE league = ?",
        (league_code,)
    )
    conn.commit()
    print(f"‚úÖ Anciennes donn√©es {league_code} supprim√©es")
    
    # 2. Re-scraper TOUTE la ligue
    scraper = AutoScraper()
    scraper.run(league_code=league_code, parallel_workers=4)
    
    conn.close()

# Appel hebdomadaire (via cron)
weekly_update("bulgaria")
weekly_update("france")
weekly_update("england")
# etc...
```

**Alternative : UPDATE/INSERT s√©lectif** (d√©j√† impl√©ment√©)

```python
# Option B : UPDATE/INSERT intelligent (PLUS COMPLEXE)
# Utilis√© dans scrape_bulgaria_auto.py save_to_db()

# Avantages :
# - Garde l'historique
# - Met √† jour seulement ce qui a chang√©

# Inconv√©nients :
# - Risque de doublons si logique cass√©e
# - Plus difficile √† debugger

# Code d√©j√† dans save_to_db() :
cursor.execute('''
    SELECT COUNT(*) FROM soccerstats_scraped_matches 
    WHERE team = ? AND opponent = ? AND date = ? AND is_home = ?
''', (match['team'], match['opponent'], match['date'], 1 if match['is_home'] else 0))

if cursor.fetchone()[0] > 0:
    # UPDATE
else:
    # INSERT
```

**‚ö†Ô∏è Recommandation :** Utiliser **Option A (DELETE + INSERT)** pour simplicit√© et fiabilit√©

---

### Planification cron (Linux/macOS)

```bash
# Ex√©cuter chaque dimanche √† 3h du matin
0 3 * * 0 cd /workspaces/paris-live && python3 weekly_scraper.py >> scraping.log 2>&1
```

**weekly_scraper.py :**
```python
#!/usr/bin/env python3
"""
Script de scraping hebdomadaire pour toutes les ligues
Ex√©cut√© automatiquement chaque semaine
"""
import sqlite3
from scrape_all_leagues_auto import AutoScraper

LEAGUES = {
    'bulgaria': 'Bulgaria',
    'france': 'France', 
    'england': 'England',
    'spain': 'Spain',
    'italy': 'Italy',
    'germany': 'Germany'
}

DB_PATH = "football-live-prediction/data/predictions.db"

def weekly_update():
    """Mise √† jour hebdomadaire de toutes les ligues"""
    
    for league_code, country in LEAGUES.items():
        print(f"\n{'='*80}")
        print(f"üîÑ MISE √Ä JOUR HEBDOMADAIRE : {country}")
        print(f"{'='*80}\n")
        
        # 1. Supprimer anciennes donn√©es
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute(
            "DELETE FROM soccerstats_scraped_matches WHERE league = ?",
            (league_code,)
        )
        deleted = cursor.rowcount
        conn.commit()
        conn.close()
        print(f"‚úÖ {deleted} anciennes entr√©es supprim√©es pour {league_code}")
        
        # 2. Re-scraper
        try:
            scraper = AutoScraper()
            scraper.run(league_code=league_code, parallel_workers=4)
            print(f"‚úÖ {country} mise √† jour avec succ√®s\n")
        except Exception as e:
            print(f"‚ùå Erreur {country}: {e}\n")
            continue

if __name__ == "__main__":
    weekly_update()
```

---

### V√©rification post-scraping

```python
def verify_data_integrity(league_code: str):
    """
    V√©rifier l'int√©grit√© des donn√©es apr√®s scraping
    """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # 1. Nombre d'√©quipes
    cursor.execute(
        "SELECT COUNT(DISTINCT team) FROM soccerstats_scraped_matches WHERE league = ?",
        (league_code,)
    )
    nb_teams = cursor.fetchone()[0]
    print(f"‚úÖ {nb_teams} √©quipes distinctes")
    
    # 2. Nombre de matchs
    cursor.execute(
        "SELECT COUNT(*) FROM soccerstats_scraped_matches WHERE league = ?",
        (league_code,)
    )
    nb_matches = cursor.fetchone()[0]
    print(f"‚úÖ {nb_matches} matchs enregistr√©s")
    
    # 3. Balance buts (CRITIQUE)
    cursor.execute("""
        SELECT SUM(goals_for), SUM(goals_against)
        FROM soccerstats_scraped_matches 
        WHERE league = ?
    """, (league_code,))
    scored, conceded = cursor.fetchone()
    
    if scored == conceded:
        print(f"‚úÖ Balance buts OK : {scored} = {conceded}")
    else:
        print(f"‚ö†Ô∏è  ALERTE Balance : {scored} ‚â† {conceded} (diff: {abs(scored-conceded)})")
    
    # 4. D√©tection doublons
    cursor.execute("""
        SELECT team, opponent, date, is_home, COUNT(*) as nb
        FROM soccerstats_scraped_matches 
        WHERE league = ?
        GROUP BY team, opponent, date, is_home
        HAVING COUNT(*) > 1
    """, (league_code,))
    
    duplicates = cursor.fetchall()
    if duplicates:
        print(f"‚ö†Ô∏è  {len(duplicates)} doublons d√©tect√©s :")
        for dup in duplicates[:5]:
            print(f"   - {dup}")
    else:
        print(f"‚úÖ Aucun doublon d√©tect√©")
    
    conn.close()

# Appeler apr√®s chaque scraping
verify_data_integrity("bulgaria")
```

---

### Logs et monitoring

```python
import logging
from datetime import datetime

# Configuration logging
logging.basicConfig(
    filename=f'scraping_{datetime.now().strftime("%Y%m%d")}.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# Dans le scraper
logging.info(f"D√©but scraping {league_code}")
logging.info(f"{nb_teams} √©quipes trouv√©es")
logging.info(f"{nb_matches} matchs scrap√©s")
logging.error(f"Erreur scraping {team_name}: {error}")
```

---

## üéØ GOLDEN RULES

1. **R√âCURRENCE = MATCHS avec but, PAS total buts**
2. **goal_times = TOUJOURS 10 √©l√©ments**
3. **76-90 = intervalle dominant (~27-30% des buts)**
4. **SELECT avant UPDATE/INSERT = pas de doublons**
5. **Throttling 2-3s = respect serveur**
6. **Validation balance : goals_for = goals_against**
7. **Scraping hebdomadaire = DELETE + INSERT complet par ligue**
8. **V√©rifier int√©grit√© apr√®s chaque scraping**

---

## üìÖ WORKFLOW COMPLET HEBDOMADAIRE

```
DIMANCHE 3h00 AM (cron)
  ‚îÇ
  ‚îú‚îÄ‚ñ∫ DELETE anciennes donn√©es Bulgaria
  ‚îú‚îÄ‚ñ∫ SCRAPE Bulgaria (16 √©quipes √ó 14 matchs)
  ‚îú‚îÄ‚ñ∫ VERIFY int√©grit√© (balance buts, doublons)
  ‚îÇ
  ‚îú‚îÄ‚ñ∫ DELETE anciennes donn√©es France
  ‚îú‚îÄ‚ñ∫ SCRAPE France (18 √©quipes √ó 14 matchs)
  ‚îú‚îÄ‚ñ∫ VERIFY int√©grit√©
  ‚îÇ
  ‚îú‚îÄ‚ñ∫ DELETE anciennes donn√©es England
  ‚îú‚îÄ‚ñ∫ SCRAPE England (20 √©quipes √ó 14 matchs)
  ‚îú‚îÄ‚ñ∫ VERIFY int√©grit√©
  ‚îÇ
  ‚îî‚îÄ‚ñ∫ ... etc pour Spain, Italy, Germany

LUNDI 8h00 AM
  ‚îÇ
  ‚îî‚îÄ‚ñ∫ ANALYSE patterns pour toutes les ligues
      ‚îú‚îÄ‚ñ∫ Calcul r√©currences 31-45 et 76-90
      ‚îú‚îÄ‚ñ∫ Classement par % r√©currence
      ‚îî‚îÄ‚ñ∫ Mise √† jour base patterns exploitables
```

---

**FIN DU DOCUMENT DE R√âF√âRENCE**

Cette m√©thodologie est **IMMUABLE** et doit √™tre suivie **√Ä LA LETTRE** pour toutes les ligues.
