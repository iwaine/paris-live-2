#!/usr/bin/env python3
"""
Test match Portugal en live
D√©tection + Analyse + Message Telegram
"""

import sys
import os
import requests
from bs4 import BeautifulSoup
import json
import sqlite3
from datetime import datetime

# Config Telegram
TELEGRAM_CONFIG = "/workspaces/paris-live/telegram_config.json"

# Charger whitelist Portugal
with open("/workspaces/paris-live/football-live-prediction/whitelists/portugal_whitelist.json", "r", encoding="utf-8") as f:
    whitelist_data = json.load(f)

print(f"‚úì Whitelist Portugal charg√©e: {len(whitelist_data['qualified_teams'])} patterns qualifi√©s")
print()

# 1. D√©tecter les matchs live Portugal
print("üîç D√âTECTION MATCHS LIVE PORTUGAL")
print("="*70)

url = "https://www.soccerstats.com/live.asp"
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
}

try:
    resp = requests.get(url, headers=headers, timeout=15)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, 'html.parser')
    
    # Trouver les matchs Portugal
    portugal_matches = []
    
    # Chercher les sections de championnat
    championship_headers = soup.find_all(['h3', 'h2', 'div'], class_=lambda x: x and 'championship' in str(x).lower())
    
    # Approche plus large : chercher tous les liens qui contiennent "portugal"
    all_links = soup.find_all('a', href=True)
    portugal_sections = [link for link in all_links if 'portugal' in link.get('href', '').lower()]
    
    if portugal_sections:
        print(f"‚úì {len(portugal_sections)} liens Portugal trouv√©s")
        
        # Chercher les tables de matchs √† proximit√©
        for section in portugal_sections[:3]:  # Limiter aux 3 premiers
            parent = section.find_parent(['div', 'table'])
            if parent:
                # Chercher les lignes de match
                match_rows = parent.find_all('tr')
                for row in match_rows:
                    cells = row.find_all('td')
                    if len(cells) >= 5:
                        # Format typique: Minute | Home | Score | Away | Stats
                        minute_cell = cells[0].get_text(strip=True)
                        
                        # V√©rifier si c'est un match en cours (minute affich√©e)
                        if minute_cell and minute_cell.replace("'", "").isdigit():
                            minute = int(minute_cell.replace("'", ""))
                            home_team = cells[1].get_text(strip=True) if len(cells) > 1 else ""
                            score = cells[2].get_text(strip=True) if len(cells) > 2 else ""
                            away_team = cells[3].get_text(strip=True) if len(cells) > 3 else ""
                            
                            if home_team and away_team and score and '-' in score:
                                portugal_matches.append({
                                    'minute': minute,
                                    'home': home_team,
                                    'away': away_team,
                                    'score': score
                                })
    
    # Affichage
    if not portugal_matches:
        print("‚ö†Ô∏è  Aucun match Portugal d√©tect√© en live")
        print()
        print("üîÑ Scraping alternatif de la page compl√®te...")
        
        # Afficher un √©chantillon de la page pour debug
        text_content = soup.get_text()
        if 'portugal' in text_content.lower() or 'liga' in text_content.lower():
            print("‚úì Contenu 'Portugal' trouv√© dans la page")
            
            # Extraire toutes les tables
            tables = soup.find_all('table')
            print(f"‚úì {len(tables)} tables trouv√©es sur la page")
            
            # Chercher dans toutes les tables
            for idx, table in enumerate(tables):
                rows = table.find_all('tr')
                for row in rows:
                    text = row.get_text()
                    if any(keyword in text.lower() for keyword in ['benfica', 'sporting', 'porto', 'braga', 'guimaraes']):
                        cells = row.find_all('td')
                        if len(cells) >= 4:
                            print(f"\nTable {idx} - Match potentiel trouv√©:")
                            for i, cell in enumerate(cells[:6]):
                                print(f"  Cell {i}: {cell.get_text(strip=True)}")
        else:
            print("‚ùå Aucun contenu Portugal trouv√©")
    else:
        print(f"‚úì {len(portugal_matches)} match(s) Portugal en live d√©tect√©(s)")
        print()
        
        for match in portugal_matches:
            print(f"‚öΩ {match['home']} vs {match['away']}")
            print(f"   Minute: {match['minute']}' | Score: {match['score']}")
            print()
            
            # Analyser si √©quipes dans whitelist
            home_qualified = any(
                t['team_name'].lower() == match['home'].lower() 
                for t in whitelist_data['qualified_teams']
            )
            away_qualified = any(
                t['team_name'].lower() == match['away'].lower() 
                for t in whitelist_data['qualified_teams']
            )
            
            if home_qualified or away_qualified:
                print("   ‚úÖ √âQUIPE(S) QUALIFI√âE(S) - Analyse n√©cessaire")
                if home_qualified:
                    print(f"      ‚Ä¢ {match['home']} (HOME)")
                if away_qualified:
                    print(f"      ‚Ä¢ {match['away']} (AWAY)")
            else:
                print("   ‚ö†Ô∏è  Aucune √©quipe qualifi√©e - Match ignor√©")
            print()

except Exception as e:
    print(f"‚ùå Erreur scraping: {e}")
    import traceback
    traceback.print_exc()

print()
print("="*70)
print("‚úÖ Test termin√©")
